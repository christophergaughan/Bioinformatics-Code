{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1qGHEVV0XOsl0dCq5ZLmDWIyAZtJjOhNq",
      "authorship_tag": "ABX9TyOmqYDNmFf5QLRt4Cuf1n1Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christophergaughan/Bioinformatics-Code/blob/main/Vasculogic_query_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3ETBYgmH-V-"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "# Load the tokenizer and NER model\n",
        "model_name = \"dslim/bert-base-NER\"  # Pre-trained NER model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# Verify it works\n",
        "print(f\"Loaded model: {model_name}\")\n"
      ],
      "metadata": {
        "id": "r-aH2N31IsI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the Excel file\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "3PDFA16jI5mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/Updated_indications_and_assets.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Display the first few rows\n",
        "print(data.head())\n",
        "\n",
        "# Get column names for reference\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "id": "2G2099qNL8yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file into a pandas DataFrame\n",
        "file_path = '/content/Updated_indications_and_assets.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Display the first few rows to understand the structure\n",
        "print(data.head())\n",
        "\n",
        "# Display the column names to reference later\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "id": "LgWnbW85Mk8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. `Example Marketed Therapies`\n",
        "* Content: List of drugs or therapies that are commonly marketed to treat the  disorder.\n",
        "* PubMed Query: `\"Marketed therapies for [Disorder]\"` or `\"FDA-approved drugs for [Disorder]\"`.\n",
        "* Example Data: `\"Aspirin; Ibuprofen; Paracetamol\"`.\n",
        "\n",
        "## 2. `Clinical Efficacy`\n",
        "* Content: Summary of the efficacy of the therapies used for the disorder, such as survival rates, progression-free survival, or effectiveness in managing symptoms.\n",
        "* PubMed Query: `\"Clinical efficacy of [Drug Name] for [Disorder]\"` or `\"Effectiveness of [Drug Name] in [Disorder]\"`.\n",
        "Example Data: \"Improves survival by 20%; Reduces relapse rate by 30%\".\n",
        "\n",
        "## 3. `Biomarkers`\n",
        "* Content: Key biomarkers associated with the disorder, which may indicate disease progression or therapeutic targets.\n",
        "* PubMed Query: `\"Biomarkers for [Disorder]\"` or `\"Genetic markers for [Disorder]\"`.\n",
        "Example Data: `\"BRCA1; BRCA2; HER2\"`.\n"
      ],
      "metadata": {
        "id": "c-_Is3W-ShLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Data Flow\n",
        "For a disorder like \"Breast Cancer\", we might populate the columns as:\n",
        "\n",
        "* `Disorder`: `\"Breast Cancer\"`\n",
        "* `Example Marketed Therapies`: `\"Trastuzumab (Herceptin); Tamoxifen; Palbociclib\"`\n",
        "* `Clinical Efficacy`: `\"Improves survival by 15%; 40% progression-free survival\"`\n",
        "`Biomarkers`: `\"HER2; BRCA1; BRCA2\"`"
      ],
      "metadata": {
        "id": "w9oGOK-5UPxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython\n"
      ],
      "metadata": {
        "id": "w8mj4vMoVtk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import Entrez\n",
        "\n",
        "print(\"Biopython installed successfully!\")\n"
      ],
      "metadata": {
        "id": "NIWmod9xVyyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Ensure the summarizer uses the GPU (device=0 for the first GPU)\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-small\", device=0)\n"
      ],
      "metadata": {
        "id": "uqUtgGmCWUtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, max_length=512):\n",
        "    words = text.split()\n",
        "    for i in range(0, len(words), max_length):\n",
        "        yield \" \".join(words[i:i + max_length])\n",
        "\n",
        "# Example usage\n",
        "text = \"Your very long input text here...\"\n",
        "chunks = list(chunk_text(text, max_length=512))\n"
      ],
      "metadata": {
        "id": "tApSVNKhWXKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = []\n",
        "for chunk in chunks:\n",
        "    summary = summarizer(chunk, max_length=50, min_length=20, do_sample=False)[0]['summary_text']\n",
        "    summaries.append(summary)\n",
        "\n",
        "# Combine summaries\n",
        "final_summary = \" \".join(summaries)\n",
        "print(final_summary)\n"
      ],
      "metadata": {
        "id": "dOgerZkrWuZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)\n"
      ],
      "metadata": {
        "id": "vfd_quhCnpio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Clinical Efficacy (PI*)'] = data['Clinical Efficacy (PI*)'].astype(str)\n"
      ],
      "metadata": {
        "id": "mcDuBl-Onxoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.rename(columns={\n",
        "    'Clinical Efficacy (PI*)': 'Clinical Efficacy',\n",
        "    'Example Marketed Therapies (Brand Names)': 'Marketed Therapies',\n",
        "    'Biomarkers': 'Biomarkers'\n",
        "}, inplace=True)\n"
      ],
      "metadata": {
        "id": "5OdzO3F6nzUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Clinical Efficacy'] = data['Clinical Efficacy'].astype(str)\n",
        "data['Marketed Therapies'] = data['Marketed Therapies'].astype(str)\n",
        "data['Biomarkers'] = data['Biomarkers'].astype(str)\n"
      ],
      "metadata": {
        "id": "ub1MPaEOn4B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required_columns = ['Clinical Efficacy', 'Marketed Therapies', 'Biomarkers']\n",
        "for col in required_columns:\n",
        "    if col not in data.columns:\n",
        "        data[col] = \"No data available\"\n"
      ],
      "metadata": {
        "id": "sD1f11d6oBZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required_columns = [\n",
        "    'Biomarkers',\n",
        "    'Example Marketed Therapies (Brand Names)',\n",
        "    'Clinical Efficacy (PI*)'\n",
        "]\n",
        "\n",
        "for col in required_columns:\n",
        "    if col not in data.columns:\n",
        "        data[col] = \"No data available\"  # Add placeholder values\n"
      ],
      "metadata": {
        "id": "cJTmFhRfoTlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Biomarkers'] = data['Biomarkers'].astype(str)\n",
        "data['Example Marketed Therapies (Brand Names)'] = data['Example Marketed Therapies (Brand Names)'].astype(str)\n",
        "data['Clinical Efficacy (PI*)'] = data['Clinical Efficacy (PI*)'].astype(str)\n"
      ],
      "metadata": {
        "id": "bFHfq3AMoZtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ensure compatible column data types\n",
        "# data['Biomarkers'] = data['Biomarkers'].astype(str)\n",
        "# data['Example Marketed Therapies (Brand Names)'] = data['Example Marketed Therapies (Brand Names)'].astype(str)\n",
        "# data['Clinical Efficacy (PI*)'] = data['Clinical Efficacy (PI*)'].astype(str)\n",
        "\n",
        "# # Populate the DataFrame\n",
        "# for index, row in data.iterrows():\n",
        "#     disorder = row['Disorder']\n",
        "\n",
        "#     # Query PubMed for Example Marketed Therapies\n",
        "#     therapy_query = f\"Marketed therapies for {disorder}\"\n",
        "#     therapy_ids = search_pubmed(therapy_query)\n",
        "#     therapy_articles = fetch_pubmed_details(therapy_ids)\n",
        "#     chunks = list(chunk_text(therapy_articles, max_length=512))\n",
        "\n",
        "#     therapies = []\n",
        "#     for chunk in chunks:\n",
        "#         inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "#         outputs = model(**inputs)\n",
        "#         predictions = torch.argmax(outputs.logits, dim=2)\n",
        "#         tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "#         labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "#         therapies.extend([token for token, label in zip(tokens, labels) if label == \"B-DRUG\"])\n",
        "#     data.at[index, 'Example Marketed Therapies (Brand Names)'] = \"; \".join(set(therapies))  # Deduplicate therapies\n",
        "\n",
        "#     # Query PubMed for Clinical Efficacy\n",
        "#     efficacy_query = f\"Clinical efficacy of therapies for {disorder}\"\n",
        "#     efficacy_ids = search_pubmed(efficacy_query)\n",
        "#     efficacy_articles = fetch_pubmed_details(efficacy_ids)\n",
        "#     efficacy_chunks = list(chunk_text(efficacy_articles, max_length=512))\n",
        "#     summaries = [summarizer(chunk, max_length=50, min_length=20, do_sample=False)[0]['summary_text']\n",
        "#                  for chunk in efficacy_chunks]\n",
        "#     data.at[index, 'Clinical Efficacy (PI*)'] = \" \".join(summaries)\n",
        "\n",
        "#     # Query PubMed for Biomarkers\n",
        "#     biomarker_query = f\"Biomarkers for {disorder}\"\n",
        "#     biomarker_ids = search_pubmed(biomarker_query)\n",
        "#     biomarker_articles = fetch_pubmed_details(biomarker_ids)\n",
        "#     biomarker_chunks = list(chunk_text(biomarker_articles, max_length=512))\n",
        "\n",
        "#     biomarkers = []\n",
        "#     for chunk in biomarker_chunks:\n",
        "#         inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "#         outputs = model(**inputs)\n",
        "#         predictions = torch.argmax(outputs.logits, dim=2)\n",
        "#         tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "#         labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "#         biomarkers.extend([token for token, label in zip(tokens, labels) if label == \"B-BIOMARKER\"])\n",
        "#     data.at[index, 'Biomarkers'] = \"; \".join(set(biomarkers))  # Deduplicate biomarkers\n",
        "\n",
        "# # Save the updated DataFrame back to Excel\n",
        "# updated_file_path = '/content/Updated_indications_and_assets_filled4.xlsx'\n",
        "# data.to_excel(updated_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "jQB7ZTOFwo6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the input column\n",
        "print(data['Disorder'].isnull().sum())  # Count NaN in the Disorder column\n",
        "print(data['Disorder'].unique())  # Check unique values for unexpected entries\n"
      ],
      "metadata": {
        "id": "AbrII_EMxpWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. The Biomarkers column is mostly missing, despite appearing to be retrievable, we can deal with this. It *might* be due to issues with:\n",
        "\n",
        "* PubMed Query Relevance: The queries used for `Biomarkers` may not match  PubMed's indexed terms for specific biomarkers.\n",
        "* NER Model Limitations: The model may not be well-suited for extracting specific scientific terms like `biomarkers` from abstracts.\n",
        "* Chunking or Processing Errors: Biomarker-related information might be split across chunks or overlooked during processing.\n",
        "\n",
        "We *can deal*\n"
      ],
      "metadata": {
        "id": "fNMnHaseNz5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strategies to Improve Biomarker Retrieval\n",
        "1. Refine PubMed Queries\n",
        "The default query format (\"Biomarkers for [Disorder]\") may not align with how biomarkers are described in PubMed. Surprise.\n",
        "\n",
        "Enhanced Query Examples:\n",
        "\n",
        "\"`Biomarkers in [Disorder]`\" (e.g., \"`Biomarkers in Lung Cancer``\")\n",
        "\"`Genetic markers for [Disorder]`\" (e.g., \"`Genetic markers for Leukemia`\")\n",
        "\"`Molecular biomarkers for [Disorder]`\"\n",
        "\n",
        "Implementation: Update the query construction for biomarkers:"
      ],
      "metadata": {
        "id": "L58g_UJDOJji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data' is your DataFrame\n",
        "for index, row in data.iterrows():\n",
        "    disorder = row['Disorder']  # Assuming 'Disorder' is the column name\n",
        "    biomarker_query = f\"Molecular biomarkers for {disorder}\""
      ],
      "metadata": {
        "id": "Y-MTWVOQPdjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Assuming 'data' is your DataFrame\n",
        "for index, row in data.iterrows():\n",
        "    disorder = row['Disorder']  # Assuming 'Disorder' is the column name\n",
        "    biomarker_query = f\"Molecular biomarkers for {disorder}\"\n",
        "    # ... (rest of your code to process the query) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wTqxkVqGhFzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Use Synonyms and Keywords\n",
        "Some disorders may have synonyms or related terms. For example:\n",
        "\n",
        "\"`Cancer`\" → \"`Tumor`\"\n",
        "\n",
        "\"`Leukemia`\" → \"`Blood cancer`\"\n",
        "\n",
        "**Create a mapping of synonyms and keywords to improve the coverage of PubMed queries:**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yh52kn2bPpuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_mapping = {\n",
        "    \"Lung Cancer\": [\"Lung Cancer\", \"Pulmonary Tumors\"],\n",
        "    \"Leukemia\": [\"Leukemia\", \"Blood Cancer\"],\n",
        "    \"Solid Tumors\": [\"lung cancer\", \"breast cancer\", \"colorectal cancer\", \"prostate cancer\", \"liver cancer\"],\n",
        "    \"Hematologic Cancers\": [\"leukemia\", \"lymphoma\", \"multiple myeloma\"],\n",
        "    \"Rare Cancers\": [\"sarcomas\", \"neuroendocrine tumors\", \"pediatric cancers\"],\n",
        "    \"Immuno-oncology\": [\"checkpoint inhibitors\", \"CAR-T therapies\"],\n",
        "    \"Neurology and Psychiatry\": [\"neurological disorders\", \"schizophrenia\", \"bipolar disorder\", \"major depression\", \"PTSD\"],\n",
        "    \"Psychiatric Disorders\": [\"schizophrenia\", \"bipolar disorder\", \"major depression\", \"PTSD\"],\n",
        "    \"Neurodegenerative Diseases\": [\"Alzheimer's Disease\", \"Parkinson's Disease\", \"ALS\"],\n",
        "    \"Neurodevelopmental Disorders\": [\"autism\", \"ADHD\"],\n",
        "    \"Seizure Disorders\": [\"epilepsy\", \"Dravet syndrome\"],\n",
        "    \"Movement Disorders\": [\"Huntington's Disease\", \"dystonia\", \"Tourette syndrome\", \"Benign Tremor\", \"Parkinson's Disease\"],\n",
        "    \"Cardiovascular Diseases\": [\n",
        "        \"Atherosclerosis\", \"Coronary Artery Disease\", \"Low-Density Lipoprotein (LDL)\", \"High-Density Lipoprotein (HDL)\",\n",
        "        \"Heart Failure\", \"Ventricular Hypertrophy\", \"Hypertension\", \"Arrhythmia\", \"Atrial Fibrillation\",\n",
        "        \"Venous Thromboembolism\", \"Peripheral Artery Disease\", \"Arteriovenous Malformation\"\n",
        "    ],\n",
        "    \"Autoimmune and Inflammatory Diseases\": [\"Rheumatoid Arthritis\", \"Psoriasis\", \"Psoriatic Arthritis\", \"Lupus\", \"Multiple Sclerosis\", \"Ankylosing Spondylitis\"],\n",
        "    \"Inflammatory Bowel Disease\": [\"Crohn's Disease\", \"Ulcerative Colitis\"],\n",
        "    \"Autoimmune Skin Disorders\": [\"atopic dermatitis\", \"vitiligo\"],\n",
        "    \"Metabolic Disorders\": [\n",
        "        \"Diabetes Type 1\", \"Diabetes Type 2\", \"Obesity\", \"Dyslipidemia\", \"Hypercholesterolemia\",\n",
        "        \"Hyperglycemia\", \"Hypoglycemia\", \"Non-Alcoholic Steatohepatitis\", \"NASH\", \"MASH\", \"Gout\",\n",
        "        \"Hyperthyroidism\", \"Hypothyroidism\"\n",
        "    ],\n",
        "    \"Rare Metabolic Disorders\": [\"lysosomal storage disease\"],\n",
        "    \"Infectious Diseases\": [\n",
        "        \"HIV\", \"AIDS\", \"COVID-19\", \"SARS\", \"Hepatitis B\", \"Hepatitis C\", \"Tuberculosis\",\n",
        "        \"Bacterial Infections\", \"antibiotic-resistant infections\", \"Fungal Infections\",\n",
        "        \"ESKAPE\", \"Malaria\", \"Dengue\"\n",
        "    ],\n",
        "    \"Respiratory Diseases\": [\"Chronic Obstructive Pulmonary Disease\", \"COPD\", \"Asthma\", \"Cystic Fibrosis\", \"Idiopathic Pulmonary Fibrosis\", \"IPF\", \"Allergic Rhinitis\"],\n",
        "    \"Rare Diseases\": [\n",
        "        \"Orphan Indications\", \"Genetic Disorders\", \"Cystic Fibrosis\", \"Duchenne Muscular Dystrophy\",\n",
        "        \"Rare Neurodegenerative and Neuromuscular Disorders\", \"Spinal Muscular Atrophy\",\n",
        "        \"Inherited Metabolic Disorders\", \"Gaucher's Disease\", \"Fabry Disease\", \"Rare Autoimmune Disorders\"\n",
        "    ],\n",
        "    \"Hematology\": [\n",
        "        \"Hemophilia\", \"Bleeding Disorders\", \"Sickle Cell Disease\", \"Thalassemia\", \"Beta Thalassemia\",\n",
        "        \"Myelodysplastic Syndromes\", \"Anemia\", \"Aplastic Anemia\"\n",
        "    ],\n",
        "    \"Endocrine Disorders\": [\"Growth Disorders\", \"Growth Hormone Deficiency\", \"Osteoporosis\", \"Cushing's Syndrome\", \"Acromegaly\"]\n",
        "}\n",
        "\n",
        "# Construct the biomarker query\n",
        "keywords = keyword_mapping.get(disorder, [disorder])\n",
        "biomarker_query = f\"Biomarkers for ({' OR '.join(keywords)})\"\n",
        "\n"
      ],
      "metadata": {
        "id": "1hvV7VNtPk5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from Bio import Entrez  # Import Entrez module\n",
        "\n",
        "def extract_biomarkers(text):\n",
        "    # Example regex for genes/proteins (can be expanded)\n",
        "    pattern = r'\\b[A-Z0-9]+(?:-[A-Z0-9]+)?\\b'  # Matches terms like \"BRCA1\", \"HER2\", etc.\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "def search_pubmed(query): # Define search_pubmed\n",
        "    Entrez.email = \"your_email@example.com\"  # Replace with your email\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=5)\n",
        "    record = Entrez.read(handle)\n",
        "    handle.close()\n",
        "    return record[\"IdList\"]\n",
        "\n",
        "def fetch_pubmed_details(id_list): # Define fetch_pubmed_details\n",
        "    ids = \",\".join(id_list)\n",
        "    handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"abstract\", retmode=\"text\")\n",
        "    records = handle.read()\n",
        "    handle.close()\n",
        "    return records\n",
        "# Example usage\n",
        "# Assuming you have data loaded in a DataFrame called 'data'\n",
        "for index, row in data.iterrows():\n",
        "    disorder = row['Disorder']  # Get the disorder from your data\n",
        "    # Assuming you have a function search_pubmed and fetch_pubmed_details\n",
        "    biomarker_query = f\"Molecular biomarkers for {disorder}\"\n",
        "    biomarker_ids = search_pubmed(biomarker_query) # get ids of pubmed articles\n",
        "    biomarker_articles = fetch_pubmed_details(biomarker_ids) #fetch articles text based on id\n",
        "    biomarkers = extract_biomarkers(biomarker_articles)\n"
      ],
      "metadata": {
        "id": "9iugeJ1ziRDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biomarker Extraction"
      ],
      "metadata": {
        "id": "kq5D3LWHqvBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shorten_text(text, max_words=1000):\n",
        "    \"\"\"Shortens a text to a maximum number of words.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to shorten.\n",
        "        max_words (int, optional): The maximum number of words to keep. Defaults to 1000.\n",
        "\n",
        "    Returns:\n",
        "        str: The shortened text.\n",
        "    \"\"\"\n",
        "    return \" \".join(text.split()[:max_words])\n"
      ],
      "metadata": {
        "id": "b5BlR9E0jZTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n"
      ],
      "metadata": {
        "id": "66SYCFBE0xoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n"
      ],
      "metadata": {
        "id": "nA2xUeQ00zaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.id2label = {0: \"O\", 1: \"B-DRUG\", 2: \"I-DRUG\", 3: \"B-BIOMARKER\", 4: \"I-BIOMARKER\"}\n"
      ],
      "metadata": {
        "id": "N5Ie-BG32Ac3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
        "from Bio import Entrez\n",
        "import time\n",
        "from http.client import IncompleteRead\n",
        "import re\n",
        "\n",
        "# Initialize summarizer pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-small\", device=0)  # Use GPU\n",
        "\n",
        "# Load the tokenizer and NER model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model.config.id2label = {0: \"O\", 1: \"B-DRUG\", 2: \"I-DRUG\", 3: \"B-BIOMARKER\", 4: \"I-BIOMARKER\"}\n",
        "\n",
        "# Helper functions\n",
        "def chunk_text(text, max_length=512):\n",
        "    tokens = text.split()\n",
        "    for i in range(0, len(tokens), max_length):\n",
        "        yield \" \".join(tokens[i:i + max_length])\n",
        "\n",
        "def shorten_text(text, max_words=1000):\n",
        "    return \" \".join(text.split()[:max_words])\n",
        "\n",
        "def fetch_pubmed_details_with_retry(id_list, retries=3, delay=5):\n",
        "    ids = \",\".join(id_list)\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"abstract\", retmode=\"text\")\n",
        "            records = handle.read()\n",
        "            handle.close()\n",
        "            return records\n",
        "        except IncompleteRead as e:\n",
        "            print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
        "            time.sleep(delay)\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
        "            time.sleep(delay)\n",
        "    return \"No data available\"\n",
        "\n",
        "def search_pubmed(query):\n",
        "    Entrez.email = \"your_email@example.com\"  # Replace with your email\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=5)\n",
        "    record = Entrez.read(handle)\n",
        "    handle.close()\n",
        "    return record[\"IdList\"]\n",
        "\n",
        "def extract_biomarkers(text):\n",
        "    pattern = r'\\b[A-Z0-9]+(?:-[A-Z0-9]+)?\\b'  # Regex for genes/proteins\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# Define keyword mapping\n",
        "keyword_mapping = {\n",
        "    \"Lung Cancer\": [\"Lung Cancer\", \"Pulmonary Tumors\"],\n",
        "    \"Leukemia\": [\"Leukemia\", \"Blood Cancer\"],\n",
        "    \"Solid Tumors\": [\"lung cancer\", \"breast cancer\", \"colorectal cancer\", \"prostate cancer\", \"liver cancer\"],\n",
        "    \"Hematologic Cancers\": [\"leukemia\", \"lymphoma\", \"multiple myeloma\"],\n",
        "    \"Rare Cancers\": [\"sarcomas\", \"neuroendocrine tumors\", \"pediatric cancers\"],\n",
        "    \"Immuno-oncology\": [\"checkpoint inhibitors\", \"CAR-T therapies\"],\n",
        "    \"Neurology and Psychiatry\": [\"neurological disorders\", \"schizophrenia\", \"bipolar disorder\", \"major depression\", \"PTSD\"],\n",
        "    \"Psychiatric Disorders\": [\"schizophrenia\", \"bipolar disorder\", \"major depression\", \"PTSD\"],\n",
        "    \"Neurodegenerative Diseases\": [\"Alzheimer's Disease\", \"Parkinson's Disease\", \"ALS\"],\n",
        "    \"Neurodevelopmental Disorders\": [\"autism\", \"ADHD\"],\n",
        "    \"Seizure Disorders\": [\"epilepsy\", \"Dravet syndrome\"],\n",
        "    \"Movement Disorders\": [\"Huntington's Disease\", \"dystonia\", \"Tourette syndrome\", \"Benign Tremor\", \"Parkinson's Disease\"],\n",
        "    \"Cardiovascular Diseases\": [\n",
        "        \"Atherosclerosis\", \"Coronary Artery Disease\", \"Low-Density Lipoprotein (LDL)\", \"High-Density Lipoprotein (HDL)\",\n",
        "        \"Heart Failure\", \"Ventricular Hypertrophy\", \"Hypertension\", \"Arrhythmia\", \"Atrial Fibrillation\",\n",
        "        \"Venous Thromboembolism\", \"Peripheral Artery Disease\", \"Arteriovenous Malformation\"\n",
        "    ],\n",
        "    \"Autoimmune and Inflammatory Diseases\": [\"Rheumatoid Arthritis\", \"Psoriasis\", \"Psoriatic Arthritis\", \"Lupus\", \"Multiple Sclerosis\", \"Ankylosing Spondylitis\"],\n",
        "    \"Inflammatory Bowel Disease\": [\"Crohn's Disease\", \"Ulcerative Colitis\"],\n",
        "    \"Autoimmune Skin Disorders\": [\"atopic dermatitis\", \"vitiligo\"],\n",
        "    \"Metabolic Disorders\": [\n",
        "        \"Diabetes Type 1\", \"Diabetes Type 2\", \"Obesity\", \"Dyslipidemia\", \"Hypercholesterolemia\",\n",
        "        \"Hyperglycemia\", \"Hypoglycemia\", \"Non-Alcoholic Steatohepatitis\", \"NASH\", \"MASH\", \"Gout\",\n",
        "        \"Hyperthyroidism\", \"Hypothyroidism\"\n",
        "    ],\n",
        "    \"Rare Metabolic Disorders\": [\"lysosomal storage disease\"],\n",
        "    \"Infectious Diseases\": [\n",
        "        \"HIV\", \"AIDS\", \"COVID-19\", \"SARS\", \"Hepatitis B\", \"Hepatitis C\", \"Tuberculosis\",\n",
        "        \"Bacterial Infections\", \"antibiotic-resistant infections\", \"Fungal Infections\",\n",
        "        \"ESKAPE\", \"Malaria\", \"Dengue\"\n",
        "    ],\n",
        "    \"Respiratory Diseases\": [\"Chronic Obstructive Pulmonary Disease\", \"COPD\", \"Asthma\", \"Cystic Fibrosis\", \"Idiopathic Pulmonary Fibrosis\", \"IPF\", \"Allergic Rhinitis\"],\n",
        "    \"Rare Diseases\": [\n",
        "        \"Orphan Indications\", \"Genetic Disorders\", \"Cystic Fibrosis\", \"Duchenne Muscular Dystrophy\",\n",
        "        \"Rare Neurodegenerative and Neuromuscular Disorders\", \"Spinal Muscular Atrophy\",\n",
        "        \"Inherited Metabolic Disorders\", \"Gaucher's Disease\", \"Fabry Disease\", \"Rare Autoimmune Disorders\"\n",
        "    ],\n",
        "    \"Hematology\": [\n",
        "        \"Hemophilia\", \"Bleeding Disorders\", \"Sickle Cell Disease\", \"Thalassemia\", \"Beta Thalassemia\",\n",
        "        \"Myelodysplastic Syndromes\", \"Anemia\", \"Aplastic Anemia\"\n",
        "    ],\n",
        "    \"Endocrine Disorders\": [\"Growth Disorders\", \"Growth Hormone Deficiency\", \"Osteoporosis\", \"Cushing's Syndrome\", \"Acromegaly\"]\n",
        "\n",
        "}\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/Updated_indications_and_assets.xlsx\"\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Ensure correct dtype for columns\n",
        "for column in ['Example Marketed Therapies (Brand Names)', 'Clinical Efficacy (PI*)', 'Biomarkers']:\n",
        "    data[column] = data[column].astype(str)\n",
        "\n",
        "# Process data\n",
        "data['Query Term'] = data['Disorder'].map(lambda d: keyword_mapping.get(d, [d]))\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    disorder = row['Query Term']\n",
        "\n",
        "    # Example Marketed Therapies\n",
        "    therapy_query = f\"Marketed therapies for ({' OR '.join(disorder)})\"\n",
        "    therapy_ids = search_pubmed(therapy_query)\n",
        "    if not therapy_ids:\n",
        "        data.at[index, 'Example Marketed Therapies (Brand Names)'] = \"No data available\"\n",
        "        continue\n",
        "    therapy_articles = shorten_text(fetch_pubmed_details_with_retry(therapy_ids))\n",
        "    therapies = []\n",
        "    for chunk in chunk_text(therapy_articles):\n",
        "        inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.argmax(outputs.logits, dim=2)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "        labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "        therapies.extend([token for token, label in zip(tokens, labels) if label == \"B-DRUG\"])\n",
        "    data.at[index, 'Example Marketed Therapies (Brand Names)'] = \"; \".join(set(therapies)) if therapies else \"No data available\"\n",
        "\n",
        "    # Clinical Efficacy\n",
        "    efficacy_query = f\"Clinical efficacy of therapies for ({' OR '.join(disorder)})\"\n",
        "    efficacy_ids = search_pubmed(efficacy_query)\n",
        "    if not efficacy_ids:\n",
        "        data.at[index, 'Clinical Efficacy (PI*)'] = \"No data available\"\n",
        "        continue\n",
        "    efficacy_articles = shorten_text(fetch_pubmed_details_with_retry(efficacy_ids))\n",
        "    summaries = [summarizer(chunk, max_length=50, min_length=10, do_sample=False)[0]['summary_text']\n",
        "                 for chunk in chunk_text(efficacy_articles)]\n",
        "    data.at[index, 'Clinical Efficacy (PI*)'] = \" \".join(summaries) if summaries else \"No data available\"\n",
        "\n",
        "    # Biomarkers\n",
        "    biomarker_query = f\"Biomarkers for ({' OR '.join(disorder)})\"\n",
        "    biomarker_ids = search_pubmed(biomarker_query)\n",
        "    if not biomarker_ids:\n",
        "        data.at[index, 'Biomarkers'] = \"No data available\"\n",
        "        continue\n",
        "    biomarker_articles = shorten_text(fetch_pubmed_details_with_retry(biomarker_ids))\n",
        "    biomarkers = []\n",
        "    for chunk in chunk_text(biomarker_articles):\n",
        "        inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.argmax(outputs.logits, dim=2)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "        labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "        biomarkers.extend([token for token, label in zip(tokens, labels) if label == \"B-BIOMARKER\"])\n",
        "    if not biomarkers:\n",
        "        biomarkers = extract_biomarkers(biomarker_articles)\n",
        "    data.at[index, 'Biomarkers'] = \"; \".join(set(biomarkers)) if biomarkers else \"No data available\"\n",
        "\n",
        "# Save updated data\n",
        "updated_file_path = \"/content/Updated_indications_and_assets_fixedV2.xlsx\"\n",
        "data.to_excel(updated_file_path, index=False)\n",
        "print(f\"Updated file saved to: {updated_file_path}\")\n"
      ],
      "metadata": {
        "id": "r9jbhC911-VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example: Distribution of populated rows per column\n",
        "populated_counts = data.notna().sum()\n",
        "populated_counts.plot(kind=\"bar\", title=\"Populated Data Counts\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tM5o1YjU-qgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates and standardize formatting for therapies\n",
        "cleaned_therapies = [therapy.capitalize() for therapy in set(therapies)]\n",
        "data.at[index, 'Example Marketed Therapies (Brand Names)'] = \"; \".join(cleaned_therapies) if cleaned_therapies else \"No data available\"\n"
      ],
      "metadata": {
        "id": "xU9O5txnOzr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = summarizer(chunk, max_length=50, min_length=20, do_sample=False)\n",
        "key_summary = \" \".join([s['summary_text'] for s in summaries[:1]])  # Only keep the first summary\n"
      ],
      "metadata": {
        "id": "tutPPZgdPFrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
        "from Bio import Entrez\n",
        "import time\n",
        "from http.client import IncompleteRead\n",
        "import re\n",
        "\n",
        "# Initialize summarizer pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-small\", device=0)  # Use GPU\n",
        "\n",
        "# Load the tokenizer and NER model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model.config.id2label = {0: \"O\", 1: \"B-DRUG\", 2: \"I-DRUG\", 3: \"B-BIOMARKER\", 4: \"I-BIOMARKER\"}\n",
        "\n",
        "# Helper functions\n",
        "def chunk_text(text, max_length=512):\n",
        "    tokens = text.split()\n",
        "    for i in range(0, len(tokens), max_length):\n",
        "        yield \" \".join(tokens[i:i + max_length])\n",
        "\n",
        "def shorten_text(text, max_words=1000):\n",
        "    return \" \".join(text.split()[:max_words])\n",
        "\n",
        "def fetch_pubmed_details_with_retry(id_list, retries=3, delay=5):\n",
        "    ids = \",\".join(id_list)\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"abstract\", retmode=\"text\")\n",
        "            records = handle.read()\n",
        "            handle.close()\n",
        "            return records\n",
        "        except IncompleteRead as e:\n",
        "            print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
        "            time.sleep(delay)\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
        "            time.sleep(delay)\n",
        "    return \"No data available\"\n",
        "\n",
        "def search_pubmed(query):\n",
        "    Entrez.email = \"your_email@example.com\"  # Replace with your email\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=5)\n",
        "    record = Entrez.read(handle)\n",
        "    handle.close()\n",
        "    return record[\"IdList\"]\n",
        "\n",
        "def extract_biomarkers(text):\n",
        "    pattern = r'\\b[A-Z0-9]+(?:-[A-Z0-9]+)?\\b'  # Regex for genes/proteins\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# Define keyword mapping\n",
        "keyword_mapping = {\n",
        "    \"Lung Cancer\": [\"Lung Cancer\", \"Pulmonary Tumors\"],\n",
        "    \"Leukemia\": [\"Leukemia\", \"Blood Cancer\"],\n",
        "    \"Solid Tumors\": [\"lung cancer\", \"breast cancer\", \"colorectal cancer\", \"prostate cancer\", \"liver cancer\"],\n",
        "    \"Hematologic Cancers\": [\"leukemia\", \"lymphoma\", \"multiple myeloma\"],\n",
        "    \"Rare Cancers\": [\"sarcomas\", \"neuroendocrine tumors\", \"pediatric cancers\"],\n",
        "    \"Immuno-oncology\": [\"checkpoint inhibitors\", \"CAR-T therapies\"],\n",
        "    \"Neurology and Psychiatry\": [\"neurological disorders\", \"schizophrenia\", \"bipolar disorder\", \"major depression\", \"PTSD\"],\n",
        "    \"Psychiatric Disorders\": [\"schizophrenia\", \"bipolar disorder\", \"major depression\", \"PTSD\"],\n",
        "    \"Neurodegenerative Diseases\": [\"Alzheimer's Disease\", \"Parkinson's Disease\", \"ALS\"],\n",
        "    \"Neurodevelopmental Disorders\": [\"autism\", \"ADHD\"],\n",
        "    \"Seizure Disorders\": [\"epilepsy\", \"Dravet syndrome\"],\n",
        "    \"Movement Disorders\": [\"Huntington's Disease\", \"dystonia\", \"Tourette syndrome\", \"Benign Tremor\", \"Parkinson's Disease\"],\n",
        "    \"Cardiovascular Diseases\": [\n",
        "        \"Atherosclerosis\", \"Coronary Artery Disease\", \"Low-Density Lipoprotein (LDL)\", \"High-Density Lipoprotein (HDL)\",\n",
        "        \"Heart Failure\", \"Ventricular Hypertrophy\", \"Hypertension\", \"Arrhythmia\", \"Atrial Fibrillation\",\n",
        "        \"Venous Thromboembolism\", \"Peripheral Artery Disease\", \"Arteriovenous Malformation\"\n",
        "    ],\n",
        "    \"Autoimmune and Inflammatory Diseases\": [\"Rheumatoid Arthritis\", \"Psoriasis\", \"Psoriatic Arthritis\", \"Lupus\", \"Multiple Sclerosis\", \"Ankylosing Spondylitis\"],\n",
        "    \"Inflammatory Bowel Disease\": [\"Crohn's Disease\", \"Ulcerative Colitis\"],\n",
        "    \"Autoimmune Skin Disorders\": [\"atopic dermatitis\", \"vitiligo\"],\n",
        "    \"Metabolic Disorders\": [\n",
        "        \"Diabetes Type 1\", \"Diabetes Type 2\", \"Obesity\", \"Dyslipidemia\", \"Hypercholesterolemia\",\n",
        "        \"Hyperglycemia\", \"Hypoglycemia\", \"Non-Alcoholic Steatohepatitis\", \"NASH\", \"MASH\", \"Gout\",\n",
        "        \"Hyperthyroidism\", \"Hypothyroidism\"\n",
        "    ],\n",
        "    \"Rare Metabolic Disorders\": [\"lysosomal storage disease\"],\n",
        "    \"Infectious Diseases\": [\n",
        "        \"HIV\", \"AIDS\", \"COVID-19\", \"SARS\", \"Hepatitis B\", \"Hepatitis C\", \"Tuberculosis\",\n",
        "        \"Bacterial Infections\", \"antibiotic-resistant infections\", \"Fungal Infections\",\n",
        "        \"ESKAPE\", \"Malaria\", \"Dengue\"\n",
        "    ],\n",
        "    \"Respiratory Diseases\": [\"Chronic Obstructive Pulmonary Disease\", \"COPD\", \"Asthma\", \"Cystic Fibrosis\", \"Idiopathic Pulmonary Fibrosis\", \"IPF\", \"Allergic Rhinitis\"],\n",
        "    \"Rare Diseases\": [\n",
        "        \"Orphan Indications\", \"Genetic Disorders\", \"Cystic Fibrosis\", \"Duchenne Muscular Dystrophy\",\n",
        "        \"Rare Neurodegenerative and Neuromuscular Disorders\", \"Spinal Muscular Atrophy\",\n",
        "        \"Inherited Metabolic Disorders\", \"Gaucher's Disease\", \"Fabry Disease\", \"Rare Autoimmune Disorders\"\n",
        "    ],\n",
        "    \"Hematology\": [\n",
        "        \"Hemophilia\", \"Bleeding Disorders\", \"Sickle Cell Disease\", \"Thalassemia\", \"Beta Thalassemia\",\n",
        "        \"Myelodysplastic Syndromes\", \"Anemia\", \"Aplastic Anemia\"\n",
        "    ],\n",
        "    \"Endocrine Disorders\": [\"Growth Disorders\", \"Growth Hormone Deficiency\", \"Osteoporosis\", \"Cushing's Syndrome\", \"Acromegaly\"]\n",
        "\n",
        "}\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/Updated_indications_and_assets.xlsx\"\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Ensure correct dtype for columns\n",
        "for column in ['Example Marketed Therapies (Brand Names)', 'Clinical Efficacy (PI*)', 'Biomarkers']:\n",
        "    data[column] = data[column].astype(str)\n",
        "\n",
        "# Process data\n",
        "data['Query Term'] = data['Disorder'].map(lambda d: keyword_mapping.get(d, [d]))\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    disorder = row['Query Term']\n",
        "\n",
        "    # Example Marketed Therapies\n",
        "    therapy_query = f\"Marketed therapies for ({' OR '.join(disorder)})\"\n",
        "    therapy_ids = search_pubmed(therapy_query)\n",
        "    if not therapy_ids:\n",
        "        data.at[index, 'Example Marketed Therapies (Brand Names)'] = \"No data available\"\n",
        "        continue\n",
        "    therapy_articles = shorten_text(fetch_pubmed_details_with_retry(therapy_ids))\n",
        "    therapies = []\n",
        "    for chunk in chunk_text(therapy_articles):\n",
        "        inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.argmax(outputs.logits, dim=2)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "        labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "        therapies.extend([token for token, label in zip(tokens, labels) if label == \"B-DRUG\"])\n",
        "    data.at[index, 'Example Marketed Therapies (Brand Names)'] = \"; \".join(set(therapies)) if therapies else \"No data available\"\n",
        "\n",
        "    # Clinical Efficacy\n",
        "    efficacy_query = f\"Clinical efficacy of therapies for ({' OR '.join(disorder)})\"\n",
        "    efficacy_ids = search_pubmed(efficacy_query)\n",
        "    if not efficacy_ids:\n",
        "        data.at[index, 'Clinical Efficacy (PI*)'] = \"No data available\"\n",
        "        continue\n",
        "    efficacy_articles = shorten_text(fetch_pubmed_details_with_retry(efficacy_ids))\n",
        "    summaries = [summarizer(chunk, max_length=50, min_length=10, do_sample=False)[0]['summary_text']\n",
        "                 for chunk in chunk_text(efficacy_articles)]\n",
        "    data.at[index, 'Clinical Efficacy (PI*)'] = \" \".join(summaries) if summaries else \"No data available\"\n",
        "\n",
        "    # Biomarkers\n",
        "    biomarker_query = f\"Biomarkers for ({' OR '.join(disorder)})\"\n",
        "    biomarker_ids = search_pubmed(biomarker_query)\n",
        "    if not biomarker_ids:\n",
        "        data.at[index, 'Biomarkers'] = \"No data available\"\n",
        "        continue\n",
        "    biomarker_articles = shorten_text(fetch_pubmed_details_with_retry(biomarker_ids))\n",
        "    biomarkers = []\n",
        "    for chunk in chunk_text(biomarker_articles):\n",
        "        inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.argmax(outputs.logits, dim=2)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "        labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "        biomarkers.extend([token for token, label in zip(tokens, labels) if label == \"B-BIOMARKER\"])\n",
        "    if not biomarkers:\n",
        "        biomarkers = extract_biomarkers(biomarker_articles)\n",
        "    data.at[index, 'Biomarkers'] = \"; \".join(set(biomarkers)) if biomarkers else \"No data available\"\n",
        "\n",
        "# Save updated data\n",
        "updated_file_path = \"/content/Updated_indications_and_assets_fixedV2_expt.xlsx\"\n",
        "data.to_excel(updated_file_path, index=False)\n",
        "print(f\"Updated file saved to: {updated_file_path}\")\n"
      ],
      "metadata": {
        "id": "veTsIW6mYreU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Import libraries\n",
        "# import pandas as pd\n",
        "# import torch\n",
        "# from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
        "# from Bio import Entrez\n",
        "# import time\n",
        "# from http.client import IncompleteRead\n",
        "# import re\n",
        "\n",
        "# # Initialize summarizer pipeline\n",
        "# summarizer = pipeline(\"summarization\", model=\"t5-small\", device=0)  # Use GPU\n",
        "\n",
        "# # Load the tokenizer and NER model\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "# model = AutoModelForTokenClassification.from_pretrained(\"allenai/scibert_scivocab_uncased\", num_labels=10)  # Adjust num_labels as per the model\n",
        "\n",
        "# # Helper functions\n",
        "# def chunk_text(text, max_length=512):\n",
        "#     tokens = text.split()\n",
        "#     for i in range(0, len(tokens), max_length):\n",
        "#         yield \" \".join(tokens[i:i + max_length])\n",
        "\n",
        "# def shorten_text(text, max_words=1000):\n",
        "#     return \" \".join(text.split()[:max_words])\n",
        "\n",
        "# def fetch_pubmed_details_with_retry(id_list, retries=3, delay=5):\n",
        "#     ids = \",\".join(id_list)\n",
        "#     for attempt in range(retries):\n",
        "#         try:\n",
        "#             handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"abstract\", retmode=\"text\")\n",
        "#             records = handle.read()\n",
        "#             handle.close()\n",
        "#             return records\n",
        "#         except IncompleteRead as e:\n",
        "#             print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
        "#             time.sleep(delay)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
        "#             time.sleep(delay)\n",
        "#     return \"No data available\"\n",
        "\n",
        "# def search_pubmed(query):\n",
        "#     Entrez.email = \"your_email@example.com\"  # Replace with your email\n",
        "#     handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=5)\n",
        "#     record = Entrez.read(handle)\n",
        "#     handle.close()\n",
        "#     return record[\"IdList\"]\n",
        "\n",
        "# # Regex-based biomarker extraction fallback\n",
        "# def extract_biomarkers(text):\n",
        "#     # Example regex for genes/proteins (can be expanded)\n",
        "#     pattern = r'\\b[A-Z0-9]+(?:-[A-Z0-9]+)?\\b'  # Matches terms like \"BRCA1\", \"HER2\", etc.\n",
        "#     return re.findall(pattern, text)\n",
        "\n",
        "# # Define keyword_mapping\n",
        "# keyword_mapping = {\n",
        "#     \"Lung Cancer\": [\"Lung Cancer\", \"Pulmonary Tumors\"],\n",
        "#     \"Leukemia\": [\"Leukemia\", \"Blood Cancer\"],\n",
        "#     \"Solid Tumors\": [\"lung cancer\", \"breast cancer\", \"colorectal cancer\", \"prostate cancer\", \"liver cancer\"],\n",
        "#     \"Hematologic Cancers\": [\"leukemia\", \"lymphoma\", \"multiple myeloma\"],\n",
        "#     \"Rare Cancers\": [\"sarcomas\", \"neuroendocrine tumors\", \"pediatric cancers\"],\n",
        "#     \"Immuno-oncology\": [\"checkpoint inhibitors\", \"CAR-T therapies\"],\n",
        "#     \"Neurology and Psychiatry\": [\"neurological disorders\", \"schizophrenia\", \"bipolar disorder\", \"major depression\", \"PTSD\"],\n",
        "#     \"Psychiatric Disorders\": [\"schizophrenia\", \"bipolar disorder\", \"major depression\", \"PTSD\"],\n",
        "#     \"Neurodegenerative Diseases\": [\"Alzheimer's Disease\", \"Parkinson's Disease\", \"ALS\"],\n",
        "#     \"Neurodevelopmental Disorders\": [\"autism\", \"ADHD\"],\n",
        "#     \"Seizure Disorders\": [\"epilepsy\", \"Dravet syndrome\"],\n",
        "#     \"Movement Disorders\": [\"Huntington's Disease\", \"dystonia\", \"Tourette syndrome\", \"Benign Tremor\", \"Parkinson's Disease\"],\n",
        "#     \"Cardiovascular Diseases\": [\n",
        "#         \"Atherosclerosis\", \"Coronary Artery Disease\", \"Low-Density Lipoprotein (LDL)\", \"High-Density Lipoprotein (HDL)\",\n",
        "#         \"Heart Failure\", \"Ventricular Hypertrophy\", \"Hypertension\", \"Arrhythmia\", \"Atrial Fibrillation\",\n",
        "#         \"Venous Thromboembolism\", \"Peripheral Artery Disease\", \"Arteriovenous Malformation\"\n",
        "#     ],\n",
        "#     \"Autoimmune and Inflammatory Diseases\": [\"Rheumatoid Arthritis\", \"Psoriasis\", \"Psoriatic Arthritis\", \"Lupus\", \"Multiple Sclerosis\", \"Ankylosing Spondylitis\"],\n",
        "#     \"Inflammatory Bowel Disease\": [\"Crohn's Disease\", \"Ulcerative Colitis\"],\n",
        "#     \"Autoimmune Skin Disorders\": [\"atopic dermatitis\", \"vitiligo\"],\n",
        "#     \"Metabolic Disorders\": [\n",
        "#         \"Diabetes Type 1\", \"Diabetes Type 2\", \"Obesity\", \"Dyslipidemia\", \"Hypercholesterolemia\",\n",
        "#         \"Hyperglycemia\", \"Hypoglycemia\", \"Non-Alcoholic Steatohepatitis\", \"NASH\", \"MASH\", \"Gout\",\n",
        "#         \"Hyperthyroidism\", \"Hypothyroidism\"\n",
        "#     ],\n",
        "#     \"Rare Metabolic Disorders\": [\"lysosomal storage disease\"],\n",
        "#     \"Infectious Diseases\": [\n",
        "#         \"HIV\", \"AIDS\", \"COVID-19\", \"SARS\", \"Hepatitis B\", \"Hepatitis C\", \"Tuberculosis\",\n",
        "#         \"Bacterial Infections\", \"antibiotic-resistant infections\", \"Fungal Infections\",\n",
        "#         \"ESKAPE\", \"Malaria\", \"Dengue\"\n",
        "#     ],\n",
        "#     \"Respiratory Diseases\": [\"Chronic Obstructive Pulmonary Disease\", \"COPD\", \"Asthma\", \"Cystic Fibrosis\", \"Idiopathic Pulmonary Fibrosis\", \"IPF\", \"Allergic Rhinitis\"],\n",
        "#     \"Rare Diseases\": [\n",
        "#         \"Orphan Indications\", \"Genetic Disorders\", \"Cystic Fibrosis\", \"Duchenne Muscular Dystrophy\",\n",
        "#         \"Rare Neurodegenerative and Neuromuscular Disorders\", \"Spinal Muscular Atrophy\",\n",
        "#         \"Inherited Metabolic Disorders\", \"Gaucher's Disease\", \"Fabry Disease\", \"Rare Autoimmune Disorders\"\n",
        "#     ],\n",
        "#     \"Hematology\": [\n",
        "#         \"Hemophilia\", \"Bleeding Disorders\", \"Sickle Cell Disease\", \"Thalassemia\", \"Beta Thalassemia\",\n",
        "#         \"Myelodysplastic Syndromes\", \"Anemia\", \"Aplastic Anemia\"\n",
        "#     ],\n",
        "#     \"Endocrine Disorders\": [\"Growth Disorders\", \"Growth Hormone Deficiency\", \"Osteoporosis\", \"Cushing's Syndrome\", \"Acromegaly\"]\n",
        "# }\n",
        "\n",
        "# # Load data\n",
        "# file_path = \"/content/Updated_indications_and_assets.xlsx\"\n",
        "# data = pd.read_excel(file_path)\n",
        "\n",
        "# # Ensure columns have the correct dtype\n",
        "# data['Example Marketed Therapies (Brand Names)'] = data['Example Marketed Therapies (Brand Names)'].astype(str)\n",
        "# data['Clinical Efficacy (PI*)'] = data['Clinical Efficacy (PI*)'].astype(str)\n",
        "# data['Biomarkers'] = data['Biomarkers'].astype(str)\n",
        "\n",
        "# # Process data\n",
        "# data['Query Term'] = data['Disorder'].map(lambda d: keyword_mapping.get(d, [d]))\n",
        "\n",
        "# for index, row in data.iterrows():\n",
        "#     disorder = row['Query Term']\n",
        "\n",
        "#     # Example Marketed Therapies\n",
        "#     therapy_query = f\"Marketed therapies for ({' OR '.join(disorder)})\"\n",
        "#     therapy_ids = search_pubmed(therapy_query)\n",
        "#     if not therapy_ids:\n",
        "#         data.at[index, 'Example Marketed Therapies (Brand Names)'] = \"No data available\"\n",
        "#         continue\n",
        "#     therapy_articles = shorten_text(fetch_pubmed_details_with_retry(therapy_ids))\n",
        "#     therapies = []\n",
        "#     for chunk in chunk_text(therapy_articles):\n",
        "#         # Ensure truncation and padding for the model's input size\n",
        "#         inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
        "#         outputs = model(**inputs)\n",
        "#         predictions = torch.argmax(outputs.logits, dim=2)\n",
        "#         tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "#         labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "#         therapies.extend([token for token, label in zip(tokens, labels) if label == \"B-DRUG\"])\n",
        "#         data.at[index, 'Example Marketed Therapies (Brand Names)'] = \"; \".join(set(therapies)) if therapies else \"No data available\"\n",
        "\n",
        "#     # Clinical Efficacy\n",
        "#     efficacy_query = f\"Clinical efficacy of therapies for ({' OR '.join(disorder)})\"\n",
        "#     efficacy_ids = search_pubmed(efficacy_query)\n",
        "#     if not efficacy_ids:\n",
        "#         data.at[index, 'Clinical Efficacy (PI*)'] = \"No data available\"\n",
        "#         continue\n",
        "#     efficacy_articles = shorten_text(fetch_pubmed_details_with_retry(efficacy_ids))\n",
        "#     summaries = [summarizer(chunk, max_length=50, min_length=10, do_sample=False)[0]['summary_text']\n",
        "#                  for chunk in chunk_text(efficacy_articles)]\n",
        "#     data.at[index, 'Clinical Efficacy (PI*)'] = \" \".join(summaries) if summaries else \"No data available\"\n",
        "\n",
        "#     # Biomarkers\n",
        "#     biomarker_query = f\"Biomarkers for ({' OR '.join(disorder)})\"\n",
        "#     biomarker_ids = search_pubmed(biomarker_query)\n",
        "#     if not biomarker_ids:\n",
        "#         data.at[index, 'Biomarkers'] = \"No data available\"\n",
        "#         continue\n",
        "#     biomarker_articles = shorten_text(fetch_pubmed_details_with_retry(biomarker_ids))\n",
        "#     biomarkers = []\n",
        "\n",
        "#     # Extract biomarkers using NER\n",
        "#     for chunk in chunk_text(biomarker_articles):\n",
        "#         inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True)\n",
        "#         outputs = model(**inputs)\n",
        "#         predictions = torch.argmax(outputs.logits, dim=2)\n",
        "#         tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "#         labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "#         biomarkers.extend([token for token, label in zip(tokens, labels) if label == \"B-BIOMARKER\"])\n",
        "\n",
        "#     # Fallback to regex if NER model misses biomarkers\n",
        "#     if not biomarkers:\n",
        "#         biomarkers = extract_biomarkers(biomarker_articles)\n",
        "\n",
        "#     # Deduplicate and store results\n",
        "#     data.at[index, 'Biomarkers'] = \"; \".join(set(biomarkers)) if biomarkers else \"No data available\"\n",
        "\n",
        "# # Save the updated data\n",
        "# updated_file_path = \"/content/Updated_indications_and_assets_fixedV2.xlsx\"\n",
        "# data.to_excel(updated_file_path, index=False)\n",
        "# print(f\"Updated file saved to: {updated_file_path}\")\n"
      ],
      "metadata": {
        "id": "aQxKkz7PxIFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l5x36I-RynKO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}