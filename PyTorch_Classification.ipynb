{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN6kLo54/l6XKvPvpNp5bDp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christophergaughan/Bioinformatics-Code/blob/main/PyTorch_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Hyperparameter             | Binary Classification                                                                                              | Multiclass Classification                                                                                  |\n",
        "|----------------------------|-------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|\n",
        "| **Input layer shape (in_features)** | Same as number of features (e.g. 5 for age, sex, height, weight, smoking status in heart disease prediction) | Same as binary classification                                                                             |\n",
        "| **Hidden layer(s)**        | Problem specific, minimum = 1, maximum = unlimited                                                               | Same as binary classification                                                                             |\n",
        "| **Neurons per hidden layer** | Problem specific, generally 10 to 512                                                                            | Same as binary classification                                                                             |\n",
        "| **Output layer shape (out_features)** | 1 (one class or the other)                                                                                  | 1 per class (e.g. 3 for food, person, or dog photo)                                                       |\n",
        "| **Hidden layer activation** | Usually ReLU (rectified linear unit) but can be many others                                                      | Same as binary classification                                                                             |\n",
        "| **Output activation**      | Sigmoid (`torch.sigmoid` in PyTorch)                                                                             | Softmax (`torch.softmax` in PyTorch)                                                                      |\n",
        "| **Loss function**          | Binary crossentropy (`torch.nn.BCELoss` in PyTorch)                                                              | Cross entropy (`torch.nn.CrossEntropyLoss` in PyTorch)                                                    |\n",
        "| **Optimizer**              | SGD (stochastic gradient descent), Adam (see `torch.optim` for more options)                                    | Same as binary classification                                                                             |\n"
      ],
      "metadata": {
        "id": "uVKHBLYJLUx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification is a problem connecting to whether one thing is identified with another"
      ],
      "metadata": {
        "id": "U-7nftIzMrSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make classification data and get it ready"
      ],
      "metadata": {
        "id": "HT05ni0-NBQn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYoqfWpsI-lt"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Make 1000 circles\n",
        "n_samples = 1000\n",
        "\n",
        "# Create circles\n",
        "X, y = make_circles(n_samples,\n",
        "                    noise = 0.03,\n",
        "                    random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(y)"
      ],
      "metadata": {
        "id": "kWrKs39mNtnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'First 5 samples of X:\\n {X[:5]}')\n",
        "print(f'First 5 samples of y:\\n {y[:5]}')"
      ],
      "metadata": {
        "id": "EVNk5PF3NzqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "SV_1vU-2OB_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clearly, we have a binary classification problem here as we have only 0's and 1's in the predictor column $(y)$"
      ],
      "metadata": {
        "id": "eyw30mjFOWbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a dataframe\n",
        "import pandas as pd\n",
        "circles = pd.DataFrame({'X1': X[:, 0],\n",
        "                        'X2': X[:, 1],\n",
        "                        'label': y})\n",
        "circles.head()"
      ],
      "metadata": {
        "id": "VMtSojY0OSy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x=X[:, 0],\n",
        "            y=X[:, 1],\n",
        "            c=y,\n",
        "            cmap=plt.cm.RdYlBu);"
      ],
      "metadata": {
        "id": "CoY2gV6LO0pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is a *toy dataset*: small enough to experiment with, but it gives us a platform to employ PyTorch code\n",
        "\n",
        "**Our goal: separate the blue dots from the red dots**"
      ],
      "metadata": {
        "id": "ch88W8SePoQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check input and output shapes\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "tSRUPJPaPO3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The data is in numpy arrays, we need to turn into pytorch tensors\n",
        "import torch\n",
        "X = torch.from_numpy(X).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.float)"
      ],
      "metadata": {
        "id": "CVcr6WPlQc2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5], y[:5]"
      ],
      "metadata": {
        "id": "2hofD8v1QrIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of X: {X.shape}')\n",
        "print(f'Shape of y: {y.shape}')"
      ],
      "metadata": {
        "id": "KodNZ4lCQvL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Values for one sample of X: {X[0]} with shape: {X[0].shape}')\n",
        "print(f'Values for one sample of y: {y[0]} with shape: {y[0].shape}')"
      ],
      "metadata": {
        "id": "_7d3YFuYQ9N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create train and test splits"
      ],
      "metadata": {
        "id": "XMGHfSv2SKM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "Om660CplRMPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.dtype, y.dtype"
      ],
      "metadata": {
        "id": "-d7tVr_oSYlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data randomly\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n"
      ],
      "metadata": {
        "id": "x0EvBfaYSvPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "id": "xGAgoCn0Ttyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model\n",
        "\n",
        "1. Device agnostoc code\n",
        "2. Construct a model by subclassing `nn.Module`\n",
        "3. loss function and optimizer\n",
        "4. Create training and test loop"
      ],
      "metadata": {
        "id": "A96B4o3oUP1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n"
      ],
      "metadata": {
        "id": "YakUu5hPTwYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Subclass `nn.Module`\n",
        "2. Create 2 `nn.Linear()` layers capable of handling the shapes in our data\n",
        "3. Define `forward()` method that outlines the forward pass\n",
        "4. Instantiate an instance of our model class and sen to target `device`"
      ],
      "metadata": {
        "id": "h28PnnBZVuZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subclass nn.Module\n",
        "class CircleModelV0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # # Create nn.Linear layers capable of handling the shapes of our data\n",
        "        # self.layer_1 = nn.Linear(in_features=2,\n",
        "        #                          out_features=5) # upscales to 5 features (hidden layers\n",
        "\n",
        "        # self.layer_2 = nn.Linear(in_features=5,\n",
        "        #                          out_features=1) # we're predicting a 0 or 1\n",
        "        self.two_linear = nn.Sequential(\n",
        "            nn.Linear(in_features=2,\n",
        "                      out_features=5),\n",
        "            nn.Linear(in_features=5,\n",
        "                      out_features=1)\n",
        "        )\n",
        "    # define the forward pass\n",
        "    def forward(self, x):\n",
        "        return self.two_linear(x)\n",
        "    #   return self.layer_2(self.layer_1(x)) # x-> layer_1 -> layer_2 -> output\n",
        "\n",
        "# Instantiate instance of model class and send to target device\n",
        "model_0 = CircleModelV0().to(device)\n",
        "model_0\n"
      ],
      "metadata": {
        "id": "kI0BAKhWVEfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note in the code above:\n",
        "\n",
        "The forward pass in the provided code may seem \"backwards\" because the sequence in which the operations are written in code starts with the last layer and progresses to the input layer, but this is simply a reflection of the computation flow in neural networks. Let's break it down:\n",
        "\n",
        "#### Understanding the forward Pass\n",
        "Order of Operations:\n",
        "\n",
        "* When you call self.layer_1(x), the input x is passed through layer_1. * This produces the intermediate output of the first layer.\n",
        "* The intermediate output is then passed to self.layer_2, which produces the final output.\n",
        "\n",
        "In functional terms:\n",
        "`x -> layer_1 -> layer_2 -> output\n",
        "`\n",
        "However, the Python code is written as:\n",
        "`return self.layer_2(self.layer_1(x))\n",
        "`\n",
        "\n",
        "This is standard practice in programming because you apply the innermost function (layer 1) first and then the outermost function (layer 2).\n",
        "\n",
        "#### Why It Feels \"Backwards\":\n",
        "\n",
        "* Neural network layers are typically thought of as a forward progression from input to output.\n",
        "* In the `forward` method, the \"nesting\" structure can feel reversed because you start with the input, apply transformations in order, but write it with the innermost function first.\n",
        "\n",
        "#### It's Just Function Composition:\n",
        "\n",
        "* The code uses function composition, where one function's output is the input to the next. This is conceptually similar to:\n",
        "`f(g(x))\n",
        "`\n"
      ],
      "metadata": {
        "id": "QXo2mjsHbzDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_0.parameters()).device"
      ],
      "metadata": {
        "id": "9b3YRciCYrJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's replicate the model above using nn.Sequential\n",
        "model_0 = nn.Sequential(\n",
        "    nn.Linear(in_features=2,\n",
        "              out_features=5),\n",
        "    nn.Linear(in_features=5,\n",
        "              out_features=1)).to(device)\n",
        "\n",
        "model_0\n"
      ],
      "metadata": {
        "id": "okPtwW4TY_wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "NKZMXPcmfAMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make preds *rmbr to use the inference mode\n",
        "with torch.inference_mode():\n",
        "    untrained_preds = model_0(X_test.to(device))\n",
        "print(f'Length of preds: {len(untrained_preds)}')\n",
        "print(f'Shape of preds: {untrained_preds.shape}')\n",
        "print(f'First 10 preds: {untrained_preds[:10]}')\n",
        "print(f'First 10 y_test: {y_test[:10]}')"
      ],
      "metadata": {
        "id": "CTSdV1G9hYRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:10], y_test[:10]"
      ],
      "metadata": {
        "id": "3ioaiiElitSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set-up loss function and optimizer\n",
        "\n",
        "Which loss and optimizer should we use?\n",
        "\n",
        "- Depends on the problem\n",
        "    - regression: MAE, MSE\n",
        "    - Classification: binary cross entropy or categorical cross entropy\n",
        "\n",
        "# Optimizer and Loss Functions in PyTorch\n",
        "\n",
        "However, the same optimizer function can often be used across different problem spaces.\n",
        "\n",
        "For example, the stochastic gradient descent optimizer (SGD, `torch.optim.SGD()`) can be used for a range of problems, and the same applies to the Adam optimizer (`torch.optim.Adam()`).\n",
        "\n",
        "| **Loss Function/Optimizer**               | **Problem Type**                   | **PyTorch Code**                        |\n",
        "|-------------------------------------------|-------------------------------------|-----------------------------------------|\n",
        "| **Stochastic Gradient Descent (SGD)**     | Classification, regression, many others. | `torch.optim.SGD()`                     |\n",
        "| **Adam Optimizer**                         | Classification, regression, many others. | `torch.optim.Adam()`                    |\n",
        "| **Binary Cross Entropy Loss**             | Binary classification               | `torch.nn.BCELossWithLogits` or `torch.nn.BCELoss` |\n",
        "| **Cross Entropy Loss**                    | Multi-class classification          | `torch.nn.CrossEntropyLoss`             |\n",
        "| **Mean Absolute Error (MAE) or L1 Loss**  | Regression                          | `torch.nn.L1Loss`                       |\n",
        "| **Mean Squared Error (MSE) or L2 Loss**   | Regression                          | `torch.nn.MSELoss`                      |\n"
      ],
      "metadata": {
        "id": "mglQZykoTc1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss function\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "tgWsGe7PjXaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "g3gb0_JjaVoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy- out of 100 examples what percentage does our model get right?\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "5k0jeebHaaNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model\n",
        "\n",
        "1. Forward pass\n",
        "2. Calculate the loss\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward (backpropagation)\n",
        "5. Optimizer step (gradient descent)"
      ],
      "metadata": {
        "id": "zqOSAp-NbgWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aslo we are going to perform the folowing:\n",
        "\n",
        "`going from raw logits -> prediction probabilities -> prediction labels`\n",
        "\n",
        "Our raw outputs from our model are logits. Convert into prediction probabilities  by passing them to some kind of activation function (e.g. sigmoid for binary classification or softmax for multiclass classificsation)\n",
        "\n",
        "Then we convert our models prediction probabilities to **prediction labels** by either rounding them or taking `argmax()`"
      ],
      "metadata": {
        "id": "cvzMb_jrcNay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0"
      ],
      "metadata": {
        "id": "JqgIrDKWbCj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 5 outputs of the forward pass on the test data\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    y_logits = model_0(X_test.to(device))[:5]\n",
        "y_logits"
      ],
      "metadata": {
        "id": "KkKHrPogdcTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "id": "ecRPonR4d3VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we are performing a binary classification- use sigmoid activation function\n",
        "y_probs = torch.sigmoid(y_logits)\n",
        "y_probs"
      ],
      "metadata": {
        "id": "kUyUw95Ye_ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our predicition probability values, we need to perform a range-style rounding on them:\n",
        "* `y_pred_probs` >= 0.5 y = 1 (class 1)\n",
        "* `y_pred+probs` < 0.5 y=0 (class 0)"
      ],
      "metadata": {
        "id": "nAkWDKorfi8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find predicition probabilities\n",
        "y_preds = torch.round(y_probs)\n",
        "\n",
        "# In full (logits->pred_probs->pred_labels)\n",
        "y_pred_labels = torch.round(torch.sigmoid(model_0(X_test.to(device))[:5]))\n",
        "y_pred_labels\n",
        "\n",
        "# Check for equality\n",
        "print(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))\n",
        "\n",
        "# Get rid of extra dimension\n",
        "y_preds.squeeze()"
      ],
      "metadata": {
        "id": "qlcVJBJqfRVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "id": "zV8KE3PLfZbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a training and test loop"
      ],
      "metadata": {
        "id": "J6Bx3QO4iJym"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omqwSLw-iHW0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}